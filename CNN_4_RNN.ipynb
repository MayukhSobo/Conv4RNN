{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:46:47.339374Z",
     "start_time": "2019-02-28T06:46:46.027527Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocess import TextReader\n",
    "from train import CNNText\n",
    "import pandas as pd\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_dev(device):\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_dev('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_dev('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the pretrained word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin',\n",
    "                                         binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process the data and convert words into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:54:22.250608Z",
     "start_time": "2019-02-28T06:54:22.239263Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_word_vectors(base_path, suffix, pretrained=False, **kwargs):\n",
    "    tr = TextReader(data_dir=base_path, \n",
    "                    suffix_labels=suffix)\n",
    "    print(tr.data_files)\n",
    "    if tr.prepare_data(clean=True, max_vocab=15000):\n",
    "        X, y = tr.get_ranked_features()\n",
    "    word_vectors_df = None\n",
    "    if pretrained:\n",
    "        model = kwargs.get('model')\n",
    "        if model is None:\n",
    "            raise ValueError('Model can not be None')\n",
    "        wv = tr.get_embedding_vector(model)\n",
    "        word_vectors = {}\n",
    "        for word, vector in wv:\n",
    "            word_vectors[tr.get_rank(word)] = vector\n",
    "        word_vectors_df = pd.DataFrame.from_dict(word_vectors, orient='index')\n",
    "    return X, y, word_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:54:23.237296Z",
     "start_time": "2019-02-28T06:54:23.088406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.py\t preprocess.py\tREADME.md\t train\r\n",
      "CNN_4_RNN.ipynb  __pycache__\trt-polarity.neg  train.py\r\n",
      "model.py\t ranks\t\trt-polarity.pos  valid\r\n",
      "nohup.out\t ranks.npy\tTFLOGS\t\t word_vectors.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:05.890246Z",
     "start_time": "2019-02-28T06:54:24.550316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 126/5331 [00:00<00:04, 1258.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./rt-polarity.pos': 1, './rt-polarity.neg': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5331/5331 [00:02<00:00, 2086.12it/s]\n",
      "100%|██████████| 5331/5331 [00:02<00:00, 1905.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y, _ = process_word_vectors('./', \n",
    "                                suffix={'rt-polarity.pos': 1, \n",
    "                                        'rt-polarity.neg': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:13.198981Z",
     "start_time": "2019-02-28T06:55:13.169040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 56)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:17.299368Z",
     "start_time": "2019-02-28T06:55:17.290605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:24.161743Z",
     "start_time": "2019-02-28T06:55:24.132735Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9595, 56)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:26.665679Z",
     "start_time": "2019-02-28T06:55:26.627895Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:28.832675Z",
     "start_time": "2019-02-28T06:55:28.762417Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('./train/X_train', X_train)\n",
    "np.save('./train/y_train', y_train)\n",
    "\n",
    "np.save('./valid/X_valid', X_test)\n",
    "np.save('./valid/y_valid', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:30.051741Z",
     "start_time": "2019-02-28T06:55:29.915259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.npy  y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:31.589585Z",
     "start_time": "2019-02-28T06:55:31.453623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid.npy  y_train.npy  y_valid.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls valid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4276\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 4298688 Mar  1 16:04 X_train.npy\r\n",
      "-rw-rw-r-- 1 paperspace paperspace   76888 Mar  1 16:04 y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the batch Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘TFLOGS’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir TFLOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:55:35.532301Z",
     "start_time": "2019-02-28T06:55:35.521354Z"
    }
   },
   "outputs": [],
   "source": [
    "cnnText = CNNText(\n",
    "    train_path='./train/',\n",
    "    valid_path='./valid/',\n",
    "    epochs=5,\n",
    "    batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:56:18.367908Z",
     "start_time": "2019-02-28T06:55:38.735327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10/955 (epoch 1/5), loss = 8.862795 (956.4 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 20/955 (epoch 1/5), loss = 5.055367 (981.5 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 30/955 (epoch 1/5), loss = 3.008179 (968.6 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 40/955 (epoch 1/5), loss = 1.922556 (1025.2 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 50/955 (epoch 1/5), loss = 1.347301 (1006.6 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 60/955 (epoch 1/5), loss = 1.052337 (942.3 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 70/955 (epoch 1/5), loss = 0.895418 (922.5 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 80/955 (epoch 1/5), loss = 0.787219 (1009.9 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 90/955 (epoch 1/5), loss = 0.755024 (988.7 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 100/955 (epoch 1/5), loss = 0.723026 (960.9 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 110/955 (epoch 1/5), loss = 0.681034 (981.9 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 120/955 (epoch 1/5), loss = 0.704127 (891.8 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 130/955 (epoch 1/5), loss = 0.688348 (907.0 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 140/955 (epoch 1/5), loss = 0.669757 (960.7 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 150/955 (epoch 1/5), loss = 0.706078 (937.3 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 160/955 (epoch 1/5), loss = 0.676355 (1031.1 examples/sec; 0.048 sec/batch), lr: 0.010000\n",
      "step 170/955 (epoch 1/5), loss = 0.692351 (960.5 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 180/955 (epoch 1/5), loss = 0.707216 (1022.5 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 190/955 (epoch 1/5), loss = 0.698583 (953.0 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "Epoch 1: training_loss = 1.925151, training_accuracy = 0.675\n",
      "Epoch 1: test_loss = 0.684012, test_accuracy = 0.702\n",
      "step 200/955 (epoch 2/5), loss = 0.687688 (890.5 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 210/955 (epoch 2/5), loss = 0.672998 (971.4 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 220/955 (epoch 2/5), loss = 0.699039 (865.9 examples/sec; 0.058 sec/batch), lr: 0.010000\n",
      "step 230/955 (epoch 2/5), loss = 0.694434 (964.2 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 240/955 (epoch 2/5), loss = 0.690061 (954.8 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 250/955 (epoch 2/5), loss = 0.693412 (1060.9 examples/sec; 0.047 sec/batch), lr: 0.010000\n",
      "step 260/955 (epoch 2/5), loss = 0.689381 (990.7 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 270/955 (epoch 2/5), loss = 0.704750 (924.9 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 280/955 (epoch 2/5), loss = 0.679275 (977.2 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 290/955 (epoch 2/5), loss = 0.711024 (977.4 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 300/955 (epoch 2/5), loss = 0.667589 (902.2 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 310/955 (epoch 2/5), loss = 0.676307 (958.6 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 320/955 (epoch 2/5), loss = 0.674992 (984.0 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 330/955 (epoch 2/5), loss = 0.671437 (974.3 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 340/955 (epoch 2/5), loss = 0.709863 (949.2 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 350/955 (epoch 2/5), loss = 0.695203 (958.5 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 360/955 (epoch 2/5), loss = 0.694553 (954.6 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 370/955 (epoch 2/5), loss = 0.711418 (897.0 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 380/955 (epoch 2/5), loss = 0.679614 (871.1 examples/sec; 0.057 sec/batch), lr: 0.010000\n",
      "Epoch 2: training_loss = 0.687137, training_accuracy = 0.709\n",
      "Epoch 2: test_loss = 0.682818, test_accuracy = 0.719\n",
      "step 390/955 (epoch 3/5), loss = 0.682738 (854.4 examples/sec; 0.059 sec/batch), lr: 0.010000\n",
      "step 400/955 (epoch 3/5), loss = 0.668238 (977.6 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 410/955 (epoch 3/5), loss = 0.690165 (935.9 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 420/955 (epoch 3/5), loss = 0.682629 (978.2 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 430/955 (epoch 3/5), loss = 0.696329 (996.7 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 440/955 (epoch 3/5), loss = 0.705002 (1010.5 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 450/955 (epoch 3/5), loss = 0.700270 (1015.4 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 460/955 (epoch 3/5), loss = 0.672714 (993.2 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 470/955 (epoch 3/5), loss = 0.686578 (953.8 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 480/955 (epoch 3/5), loss = 0.679649 (1024.1 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 490/955 (epoch 3/5), loss = 0.709396 (948.5 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 500/955 (epoch 3/5), loss = 0.668565 (1012.0 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 510/955 (epoch 3/5), loss = 0.682013 (867.2 examples/sec; 0.058 sec/batch), lr: 0.010000\n",
      "step 520/955 (epoch 3/5), loss = 0.694453 (910.4 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 530/955 (epoch 3/5), loss = 0.659660 (923.3 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 540/955 (epoch 3/5), loss = 0.703782 (927.5 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 550/955 (epoch 3/5), loss = 0.692036 (889.3 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 560/955 (epoch 3/5), loss = 0.717306 (1001.7 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 570/955 (epoch 3/5), loss = 0.687033 (979.7 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "Epoch 3: training_loss = 0.686484, training_accuracy = 0.710\n",
      "Epoch 3: test_loss = 0.681849, test_accuracy = 0.719\n",
      "step 580/955 (epoch 4/5), loss = 0.692783 (955.3 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 590/955 (epoch 4/5), loss = 0.684589 (993.5 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 600/955 (epoch 4/5), loss = 0.661579 (1011.7 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 610/955 (epoch 4/5), loss = 0.685596 (992.5 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 620/955 (epoch 4/5), loss = 0.687809 (925.7 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 630/955 (epoch 4/5), loss = 0.673938 (977.3 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 640/955 (epoch 4/5), loss = 0.698857 (944.3 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 650/955 (epoch 4/5), loss = 0.683611 (889.6 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 660/955 (epoch 4/5), loss = 0.676048 (910.1 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 670/955 (epoch 4/5), loss = 0.682294 (902.0 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 680/955 (epoch 4/5), loss = 0.665997 (948.4 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 690/955 (epoch 4/5), loss = 0.694280 (914.9 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 700/955 (epoch 4/5), loss = 0.683344 (944.4 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 710/955 (epoch 4/5), loss = 0.674366 (965.8 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 720/955 (epoch 4/5), loss = 0.687224 (939.1 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 730/955 (epoch 4/5), loss = 0.696818 (904.3 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 740/955 (epoch 4/5), loss = 0.673384 (936.8 examples/sec; 0.053 sec/batch), lr: 0.010000\n",
      "step 750/955 (epoch 4/5), loss = 0.665361 (927.0 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "step 760/955 (epoch 4/5), loss = 0.714241 (921.7 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "Epoch 4: training_loss = 0.686298, training_accuracy = 0.708\n",
      "Epoch 4: test_loss = 0.681545, test_accuracy = 0.718\n",
      "step 770/955 (epoch 5/5), loss = 0.670429 (979.1 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 780/955 (epoch 5/5), loss = 0.662310 (901.8 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 790/955 (epoch 5/5), loss = 0.689322 (1002.1 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 800/955 (epoch 5/5), loss = 0.675925 (1003.6 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 810/955 (epoch 5/5), loss = 0.666479 (986.5 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 820/955 (epoch 5/5), loss = 0.723288 (993.2 examples/sec; 0.050 sec/batch), lr: 0.010000\n",
      "step 830/955 (epoch 5/5), loss = 0.714648 (912.2 examples/sec; 0.055 sec/batch), lr: 0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 840/955 (epoch 5/5), loss = 0.677697 (956.6 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 850/955 (epoch 5/5), loss = 0.691320 (952.5 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 860/955 (epoch 5/5), loss = 0.679952 (905.3 examples/sec; 0.055 sec/batch), lr: 0.010000\n",
      "step 870/955 (epoch 5/5), loss = 0.675361 (888.5 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 880/955 (epoch 5/5), loss = 0.690552 (973.1 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 890/955 (epoch 5/5), loss = 0.668033 (975.9 examples/sec; 0.051 sec/batch), lr: 0.010000\n",
      "step 900/955 (epoch 5/5), loss = 0.668115 (879.4 examples/sec; 0.057 sec/batch), lr: 0.010000\n",
      "step 910/955 (epoch 5/5), loss = 0.674631 (834.0 examples/sec; 0.060 sec/batch), lr: 0.010000\n",
      "step 920/955 (epoch 5/5), loss = 0.681170 (899.9 examples/sec; 0.056 sec/batch), lr: 0.010000\n",
      "step 930/955 (epoch 5/5), loss = 0.724435 (954.6 examples/sec; 0.052 sec/batch), lr: 0.010000\n",
      "step 940/955 (epoch 5/5), loss = 0.674666 (1015.8 examples/sec; 0.049 sec/batch), lr: 0.010000\n",
      "step 950/955 (epoch 5/5), loss = 0.680239 (927.2 examples/sec; 0.054 sec/batch), lr: 0.010000\n",
      "Epoch 5: training_loss = 0.685934, training_accuracy = 0.708\n",
      "Epoch 5: test_loss = 0.681082, test_accuracy = 0.720\n"
     ]
    }
   ],
   "source": [
    "cnnText.train(tolerance=0.01, logdir='./TFLOGS/',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
