{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import TextReader\n",
    "from model import CNNText\n",
    "\n",
    "import pandas as pd\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the pretrained word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin',\n",
    "                                         binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process the data and convert words into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_vectors(model, base_path, suffix):\n",
    "    tr = TextReader(data_dir=base_path, \n",
    "                    suffix_labels=suffix)\n",
    "    print(tr.data_files)\n",
    "    if tr.prepare_data(clean=True):\n",
    "        X, y = tr.get_ranked_features()\n",
    "    wv = tr.get_embedding_vector(model)\n",
    "    word_vectors = {}\n",
    "    for word, vector in wv:\n",
    "        word_vectors[tr.get_rank(word)] = vector\n",
    "    word_vectors_df = pd.DataFrame.from_dict(word_vectors, orient='index')\n",
    "    return X, y, word_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./rt-polarity.pos': 1, './rt-polarity.neg': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5331/5331 [00:17<00:00, 313.34it/s]\n",
      "100%|██████████| 5331/5331 [00:17<00:00, 310.30it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y, wv = process_word_vectors(model, './', \n",
    "                                suffix={'rt-polarity.pos': 1, \n",
    "                                        'rt-polarity.neg': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 51)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./train/X_train', X_train)\n",
    "np.save('./train/y_train', y_train)\n",
    "\n",
    "np.save('./valid/X_valid', X_test)\n",
    "np.save('./valid/y_train', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.npy  y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid.npy  y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls valid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the batch Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnText = CNNText(\n",
    "    train_path='./train/',\n",
    "    valid_path='./valid/',\n",
    "    epochs=50,\n",
    "    batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|##########| 170/170 [00:00<00:00, 613.77it/s, train_loss=17, valid_loss=17]    \n",
      "Epoch 2: 100%|##########| 170/170 [00:00<00:00, 660.08it/s, train_loss=17.1, valid_loss=17.1]\n",
      "Epoch 3: 100%|##########| 170/170 [00:00<00:00, 653.58it/s, train_loss=17.2, valid_loss=17.2]\n",
      "Epoch 4: 100%|##########| 170/170 [00:00<00:00, 774.41it/s, train_loss=17.3, valid_loss=17.3]\n",
      "Epoch 5: 100%|##########| 170/170 [00:00<00:00, 582.93it/s, train_loss=17.4, valid_loss=17.4]\n",
      "Epoch 6: 100%|##########| 170/170 [00:00<00:00, 622.91it/s, train_loss=17.5, valid_loss=17.5]\n",
      "Epoch 7: 100%|##########| 170/170 [00:00<00:00, 616.63it/s, train_loss=17.6, valid_loss=17.6]\n",
      "Epoch 8: 100%|##########| 170/170 [00:00<00:00, 581.04it/s, train_loss=17.7, valid_loss=17.7]\n",
      "Epoch 9: 100%|##########| 170/170 [00:00<00:00, 679.38it/s, train_loss=17.8, valid_loss=17.8]\n",
      "Epoch 10: 100%|##########| 170/170 [00:00<00:00, 614.12it/s, train_loss=17.9, valid_loss=17.9]\n",
      "Epoch 11: 100%|##########| 170/170 [00:00<00:00, 1034.00it/s, train_loss=18, valid_loss=18]    \n",
      "Epoch 12: 100%|##########| 170/170 [00:00<00:00, 619.44it/s, train_loss=18.1, valid_loss=18.1]\n",
      "Epoch 13: 100%|##########| 170/170 [00:00<00:00, 604.48it/s, train_loss=18.2, valid_loss=18.2]\n",
      "Epoch 14: 100%|##########| 170/170 [00:00<00:00, 573.37it/s, train_loss=18.3, valid_loss=18.3]\n",
      "Epoch 15: 100%|##########| 170/170 [00:00<00:00, 665.66it/s, train_loss=18.4, valid_loss=18.4]\n",
      "Epoch 16: 100%|##########| 170/170 [00:00<00:00, 597.57it/s, train_loss=18.5, valid_loss=18.5]\n",
      "Epoch 17: 100%|##########| 170/170 [00:00<00:00, 558.91it/s, train_loss=18.6, valid_loss=18.6]\n",
      "Epoch 18: 100%|##########| 170/170 [00:00<00:00, 612.73it/s, train_loss=18.7, valid_loss=18.7]\n",
      "Epoch 19: 100%|##########| 170/170 [00:00<00:00, 572.90it/s, train_loss=18.8, valid_loss=18.8]\n",
      "Epoch 20: 100%|##########| 170/170 [00:00<00:00, 656.61it/s, train_loss=18.9, valid_loss=18.9]\n",
      "Epoch 21: 100%|##########| 170/170 [00:00<00:00, 621.20it/s, train_loss=19, valid_loss=19]    \n",
      "Epoch 22: 100%|##########| 170/170 [00:00<00:00, 593.45it/s, train_loss=19.1, valid_loss=19.1]\n",
      "Epoch 23: 100%|##########| 170/170 [00:00<00:00, 648.54it/s, train_loss=19.2, valid_loss=19.2]\n",
      "Epoch 24: 100%|##########| 170/170 [00:00<00:00, 739.25it/s, train_loss=19.3, valid_loss=19.3]\n",
      "Epoch 25: 100%|##########| 170/170 [00:00<00:00, 628.10it/s, train_loss=19.4, valid_loss=19.4]\n",
      "Epoch 26: 100%|##########| 170/170 [00:00<00:00, 533.01it/s, train_loss=19.5, valid_loss=19.5]\n",
      "Epoch 27: 100%|##########| 170/170 [00:00<00:00, 713.47it/s, train_loss=19.6, valid_loss=19.6]\n",
      "Epoch 28: 100%|##########| 170/170 [00:00<00:00, 550.24it/s, train_loss=19.7, valid_loss=19.7]\n",
      "Epoch 29: 100%|##########| 170/170 [00:00<00:00, 676.13it/s, train_loss=19.8, valid_loss=19.8]\n",
      "Epoch 30: 100%|##########| 170/170 [00:00<00:00, 604.96it/s, train_loss=19.9, valid_loss=19.9]\n",
      "Epoch 31: 100%|##########| 170/170 [00:00<00:00, 690.97it/s, train_loss=20, valid_loss=20]    \n",
      "Epoch 32: 100%|##########| 170/170 [00:00<00:00, 631.23it/s, train_loss=20.1, valid_loss=20.1]\n",
      "Epoch 33: 100%|##########| 170/170 [00:00<00:00, 593.57it/s, train_loss=20.2, valid_loss=20.2]\n",
      "Epoch 34: 100%|##########| 170/170 [00:00<00:00, 606.39it/s, train_loss=20.3, valid_loss=20.3]\n",
      "Epoch 35: 100%|##########| 170/170 [00:00<00:00, 617.12it/s, train_loss=20.4, valid_loss=20.4]\n",
      "Epoch 36: 100%|##########| 170/170 [00:00<00:00, 706.44it/s, train_loss=20.5, valid_loss=20.5]\n",
      "Epoch 37: 100%|##########| 170/170 [00:00<00:00, 663.61it/s, train_loss=20.6, valid_loss=20.6]\n",
      "Epoch 38: 100%|##########| 170/170 [00:00<00:00, 576.12it/s, train_loss=20.7, valid_loss=20.7]\n",
      "Epoch 39: 100%|##########| 170/170 [00:00<00:00, 664.75it/s, train_loss=20.8, valid_loss=20.8]\n",
      "Epoch 40: 100%|##########| 170/170 [00:00<00:00, 805.49it/s, train_loss=20.9, valid_loss=20.9]\n",
      "Epoch 41: 100%|##########| 170/170 [00:00<00:00, 591.43it/s, train_loss=21, valid_loss=21]    \n",
      "Epoch 42: 100%|##########| 170/170 [00:00<00:00, 576.54it/s, train_loss=21.1, valid_loss=21.1]\n",
      "Epoch 43: 100%|##########| 170/170 [00:00<00:00, 669.54it/s, train_loss=21.2, valid_loss=21.2]\n",
      "Epoch 44: 100%|##########| 170/170 [00:00<00:00, 643.08it/s, train_loss=21.3, valid_loss=21.3]\n",
      "Epoch 45: 100%|##########| 170/170 [00:00<00:00, 644.07it/s, train_loss=21.4, valid_loss=21.4]\n",
      "Epoch 46: 100%|##########| 170/170 [00:00<00:00, 649.74it/s, train_loss=21.5, valid_loss=21.5]\n",
      "Epoch 47: 100%|##########| 170/170 [00:00<00:00, 618.08it/s, train_loss=21.6, valid_loss=21.6]\n",
      "Epoch 48: 100%|##########| 170/170 [00:00<00:00, 646.32it/s, train_loss=21.7, valid_loss=21.7]\n",
      "Epoch 49: 100%|##########| 170/170 [00:00<00:00, 576.61it/s, train_loss=21.8, valid_loss=21.8]\n",
      "Epoch 50: 100%|##########| 170/170 [00:00<00:00, 608.45it/s, train_loss=21.9, valid_loss=21.9]\n"
     ]
    }
   ],
   "source": [
    "cnnText.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N // batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, X, y):\n",
    "    N = X.shape[0]\n",
    "    pointer = 0\n",
    "    for e in range(epochs):\n",
    "        x_out = X[pointer: pointer+batch_size, :]\n",
    "        y_out = y[pointer: pointer+batch_size]\n",
    "#         for bs in range(batch_size):\n",
    "        x_out.append(X[(pointer + bs) % N])\n",
    "        print(x_out)\n",
    "        pointer += batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 51)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 12,\n",
       " 15,\n",
       " 18,\n",
       " 21,\n",
       " 24,\n",
       " 27,\n",
       " 30,\n",
       " 33,\n",
       " 36,\n",
       " 39,\n",
       " 42,\n",
       " 45,\n",
       " 48,\n",
       " 51,\n",
       " 54,\n",
       " 57,\n",
       " 60,\n",
       " 63]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*range(0, 65, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
